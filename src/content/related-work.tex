\chapter{Related Work}  
\label{Related Work}
We are not aware of any work that optimizes NCAs using the variance over the outputs. In this respect, the present work is exploratory. Nevertheless, the work can, of course, be thematically located in other areas. The most important ones are presented here: Neural Cellular Automata (\autoref{relatedWork:NCAs}), Medical Image Segmentation (\autoref{relatedWork:medImageSegmentation}), and Robustness Improving (\autoref{relatedWork:robustImproving}). These areas span the scope of this thesis. The related work on these topics is presented in this chapter.


%%%% NCA %%%%
\section{Neural Cellular Automata}
\label{relatedWork:NCAs}
Neural Cellular Automata (NCAs), as methodically presented in \autoref{methods:NCA}, were introduced in 2019 by \cite{Gilpin:2019:IntroduceNCA} and have since been used and tested in a variety of application areas like imaging \cite{palm:2022:vnca} and robotics \cite{Horibe:2021:softRoboNCA}. They are based on Cellular Automata (\autoref{methods:CA}). For NCAs, the main function of the CA, the update rule, is learned using neural networks. NCAs can be used wherever a neighborhood field can be formalized by similar cells, and the behavior of these cells can be described by discrete time steps. The update rule is based only on one cell itself and its direct neighbors, and all cells always execute the same update rule in every time step. In an NCA, this update rule is learned by a neural network.\\
NCAs work only on a local neighborhood, i.e., they are bound to small filter sizes (e.g., 3x3) and apply the same update rule iteratively on the input. Therefore they require far fewer parameters than models that directly process global information with larger filters and applying the model-function only once. NCAs are, therefore, very small. To still process global properties, NCAs are using hidden channels for each cell, larger than the input. This allows global information to propagate from cell to cell. \cite{Gilpin:2019:IntroduceNCA}\\
NCAs show good robustness in several applications, especially for imaging. \cite{mordvintsev:2020:growingNCA} For example, NCAs are used to grow and prepare images using this concept. But only one fixed image per NCA. The concept has different stability with different figures. In \cite{mordvintsev:2021:textureNCAs}, the concept is applied to texture generation. Here, the strengths and weaknesses of NCAs become very visible. Textures for which plausible local information is sufficient to build them are generated well by NCAs. Textures that rely on more global information work poorly or not at all. \cite{otte:2021:generativeNCAs} and \cite{palm:2022:vnca} show that individual NCAs can also be used to generate different images of the same type using different seeds.


Apart from \cite{kalkhof:2023:medNCA} and \cite{kalkhof:2023:M3D-NCA}, whose work we directly follow, we are aware of only one other work that uses NCAs in image segmentation \cite{sandler:2020:imageSegNCA}. However, NCAs are also used in many other areas, such as music data generation \cite{Delaroso:MusikNCA}, reservoir computing \cite{McDonald:ReservoirNCAs}, cryptography \cite{Abdo:KryptoNCA}, FPGA placement \cite{Lyke:FPGA-NCA}, pattern recognition \cite{Wali:2022:patternNCA}, and environmental prediction \cite{Aldabbagh:2022:DessertNCA} and urban development \cite{Cevendran:2019:CityNCA}, as well as in robotics for control \cite{variengien:2021:roboNCA} and simulation of soft robot regeneration \cite{Horibe:2021:softRoboNCA}.


%%%% med Image Segmentation / Analysis %%%%
\section{Medical Image Segmentation}
\label{relatedWork:medImageSegmentation}
As mentioned in \autoref{relatedWork:NCAs}, apart from \cite{kalkhof:2023:medNCA} and \cite{kalkhof:2023:M3D-NCA}, whose work we directly follow, we are aware of only one other work using NCAs in the field of image segmentation \cite{sandler:2020:imageSegNCA}. However, image segmentation, in general, is a fundamental topic in digital image analysis and has been widely studied,as various studies show, both older (e.g., \cite{Fu:1981:ImageSegmentation_survey}) and recent (e.g., \cite{Merchant:2023:ImageSegmentation_survey}), and is still subject of current research. This is especially true for image analysis and segmentation in the medical field in the last decade, as \cite{Maier-Hain:2018:BioMedAnalysisOverview/Ranking} points out based on the  increasing competitions. In the field of image analysis, there has been a significant increase in interest, particularly in the area of image segmentation, which accounts for 70\% of all biomedical image analysis competitions.


Machine learning brings new promise as an accelerator for clinical practice with medical images. In particular, for diagnostics and AI-accelerated surgery \cite{Litjens:2017:DeepLMedImages_Survey, Varaquaux:2022:medMLFailuresFuture}. However, as \cite{Varaquaux:2022:medMLFailuresFuture} points out, while software applications are beginning to be certified for clinical use, and it is quite possible that ML will deliver on the many promises it holds for improving patient health, developments in scientific research often do not translate into clinical progress. This is a current problem throughout the field. One problem for that is the size of the models \cite{kalkhof:2023:medNCA}. For example, the state-of-the-art nnU-Net \cite{Isensee:2021:nnU-Net} defines 4 GB of VRAM as a minimum requirement, and this requires appropriate hardware and infrastructure in the domain. There are commercially available models for image segmentation, such as the Python 'Segmentation Models' package \cite{Iakubovskii:2019:PythonSegmentationModels}, but these UNet-style models all do require millions or even tens of millions parameters, while Med-NCA requires 70 thousand. This is directly due to the diffrent NCA model architecture \cite{kalkhof:2023:medNCA}. Current state-of-the-art segmentation models use a pyramid-like structure with multiple up- and downscaling blocks. However, NCAs act on individual pixels and communicate global information iteratively, and therefore, they can be tiny and run on minimal hardware. For example, the Med-NCA can run on a Raspberry Pi B+, which requires only a 5-watt power source and costs (US\$35). \cite{kalkhof:2023:medNCA}


%%%% Robustness %%%%
\section{Robustness Improving}
\label{relatedWork:robustImproving}
%%% Robustness  Reminder
In this paper, we use the term robustness in the context of perturbations in the training data. One model is more robust than another if perturbations in the training data have less of a negative impact on the quality of the model. In other words, if the distance between the predictions and the ground truth labels deteriorates less in the presence of a loss. This thesis considers two areas relevant to medical practice where machine learning models have problems. First, image artifacts that can occur during image acquisition, and second, domain shifts. Improving robustness in these two areas is crucial, not only in medical image segmentation, and is, therefore, a very active area of research, in general, \cite{Zhou:2023:DomainGeneralization_alsoAugmentation} and in medical imaging \cite{Yan:2019:DomainShiftsInMedSeg, Zhou:2023:DomainGeneralization_alsoAugmentation}. However, we could not find related work on NCAs, except for \cite{kalkhof:2023:medNCA, kalkhof:2023:M3D-NCA}.


%%% Artefakte
Artifacts or radiological noise can occur in the image generation process, from simple noise to ghosting and spiking. This can be the case in the training data and a later application. Segmentations of machine learning models often become worse. To make models more robust against such artifacts, one approach is to augment datasets with artificially generated artifacts \cite{Zhou:2023:DomainGeneralization_alsoAugmentation}. In the medical field, for example, the 'Augmentation' package of the Python library torchIO \cite{torchIO} has been established for this purpose.\\
In the literature, image artifacts are sometimes subsumed under this as a type of domain shifts, e.g., \cite{Zhou:2023:DomainGeneralization_alsoAugmentation}. In this thesis, we separate these two terms.


%%% Domain Shifts
Domain shifts in general \cite{Zhou:2023:DomainGeneralization_alsoAugmentation} occur when data comes from different sources, such as hospitals or devices. Even minor differences are often enough to lead to poor or missing segmentations \cite{Baum:2023:medDomainShifts}. This can be the case if domains are not represented in the training data but appear during use. In addition, a model may become more unstable, i.e., less predictive, when data from different domains are merged into a training set, e.g., to mitigate or avoid the former case (domain adaptation). In practice, there may be an unpredictable number of domains in this sense. Therefore, a model can only know data from some domains, especially not future domains that may arise, for example, from new devices on the market. The domain shifts can be very different and unexpected \cite{Yan:2019:DomainShiftsInMedSeg, kondrateva:2020:domainShifts}. Several frameworks have been developed in the medical field to overcome domain shifts without reference to NCA, e.g., \cite{Baum:2023:medDomainShifts, Saunders:2021:DataLimitedprostSeg, Liu:2020:MS-Net:RobustProstSegmentation}.