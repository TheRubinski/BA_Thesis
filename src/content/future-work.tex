\chapter{Future Work}
\label{future_work}
In this thesis, we have shown that it is possible to pull the NQM inside the training circle to improve the robustness of NCAs. We developed a working approach, improved it further, identified some dead ends, and, according to the explorative approach we chose, we also identified ways for further improvement. In this chapter, we will focus on the last one.


%%%% Das wichtigste: Eigenkritik/ NQM-Kritik, Ressourcenalternativen und Grundlegendere Effekte? %%%%
First and foremost, two fundamental critical questions arise about the basic approach of including the NQM, which this thesis has not investigated.
\textbf{First,} do more fundamental effects than the NQM play a role in the functioning model-dataset constellations? For Example, a batch multiplication hidden by the output stack generation in the NQM comes into question. The loss has more information when training on the DiceBceNQM, independent of the loss itself, simply because stacksize many outputs are generated. Testing whether a model with the DiceBCE on such an output stack is as robust as with the DiceBceNQM is reasonable.
Moreover, suppose we assume that the Med-NCA brings quite similar robustness on the DiceBCE, as the Backbone-NCA does on the DiceBceNQM, because of the Med-NCA architecture. In that case, it is close to assuming that another architecture can bring more robustness than "messing around" with the loss and the NQM. E.g., by a deeper or broader hierarchy.
\textbf{Secondly,} can better effects be achieved with more straightforward or different approaches using the same resources? All conceivable alternatives come into question, first of all, simple things like increasing the batch size or the training time (in the best case until convergence) until the DiceBCE consumes as much VRAM or time as the DiceBceNQM. So far, we have primarily used the default settings of the existing framework, as far as resource-technically possible, and the models to be compared were always trained with the same parameters, regardless of resource usage. For an exploration, our approach is reasonable; for usage, the resource question is at least as important.


%%%% open strains
Furthermore, in favor of a more extensive exploration, some test strains are not finalized. Particularly concerning the strong scattering of Med-NCA. \textbf{First,} whether the stabilizations that we were able to achieve with pre-trained models and extended training time in the Med-NCA for the augmented data (\autoref{tab:03.2.1:medNCA_Prost:on_Spike}) are also transferable to the domain shifts (\autoref{experiments:03.2.2:med_prost:onDomainShifts}), has not been tested. Even if the experimental costellation and the problematic scattering results are very similar in both cases. \textbf{Secondly,} whether only a long training period totaling 3000 epochs made the difference or only using a pretrained model or both. \textbf{Thirdly,} since our approach with the Med-NCA has so far led to a stabilization of the results because they no longer scatter downwards but to no improvement in robustness, the question arises as to whether the outliers \textit{upwards} can be made usable. In particular, models that scatter strongly upwards are often positive on all test datasets (Noise 0.2, Spike 0.1, Spike 0.2). If we assume that by adding the NQM, the high-dimensional solution space forms minima in more robust solutions but at the same time becomes stupidly more complex, it is conceivable that more robust models can be found with skillful control. For example, switching from DiceBCE to DiceBceNQM at the right moment or possibly more often. 
\textbf{Fourthly,} the loss can be developed further by testing if increasing the alpha further in the linear DiceBceNQM brings additional improvement or faster convergence. In \autoref{experiments:03.1.x:FurtherNQMLosses}, we tested whether the non-linear losses work at all. To check which of all working losses converges the fastest, to minimize the training time, would be a next step there. As well as testing, if the powNQM with a higher base than 3 works well, to test cubic root or a mixture of power and root functions in the sense of powNQM -1 + sqrtNQM, we consider sensible. Moreover, since we cut the NQM to the interval $(0,1)$ before we started with the robustness tests, it would also be interesting to see if there is a performance difference in not cropping.


%%%% Alternativen zu NQM als loss
Beyond that, we see further alternatives we did not touch at all but are worth noting.
\textbf{First,} instead of making the NQM usable by integrating it into the loss, another approach would be to use a periodic duplication of the volumes an intermediate model performs poorly on in the sence of the NQM. 
\textbf{Secondly,} since the NQM alone does not work as a loss because the label is not taken into account, the NQM could be further modified, by using the variance over the output-label-difference, instead of using only the variance over the outputs.